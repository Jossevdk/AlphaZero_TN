
Loading environment from: sessions/testing2

Starting iteration 1

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 1.9
    MCTS memory footprint per worker: 328.62MB
    Experience buffer size: 2,378 (2,113 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
           0.06948913      0.026481671       0.04205503    0.00031656597     1.3822803e-9        3.2051556        3.2378879
           0.06896999      0.026904223       0.04108054     0.0003068495     1.0897909e-9        3.2051556         3.247202
    
    Launching a checkpoint evaluation
    
      Average reward: -0.25, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
           0.06896999      0.026904223       0.04108054     0.0003068495     1.0897909e-9        3.2051556         3.247202
           0.06672038      0.025221366       0.04058372    0.00028631085     1.6390466e-9        3.2051556        3.2445643
    
    Launching a checkpoint evaluation
    
      Average reward: -0.06, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
           0.06672038      0.025221366       0.04058372    0.00028631085     1.6390466e-9        3.2051556        3.2445643
           0.06792255      0.026444634      0.040522672    0.00028129428   -1.1981831e-10        3.2051556        3.2481668
    
    Launching a checkpoint evaluation
    
      Average reward: -0.19, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -1.00, redundancy: 9.5%

Training completed


Loading environment from: sessions/testing2

Starting iteration 2

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 1.9
    MCTS memory footprint per worker: 276.81MB
    Experience buffer size: 4,626 (4,086 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
           0.05677776      0.018269446       0.03751525    0.00028129425    -1.4839198e-9        3.2295475        3.2690177
          0.055337638      0.017448016      0.036911752     0.0002609323    6.8086464e-10        3.2295475        3.2690034
    
    Launching a checkpoint evaluation
    
      Average reward: -0.09, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
          0.055337638      0.017448016      0.036911752     0.0002609323    6.8086464e-10        3.2295475        3.2690034
           0.05543453       0.01792883      0.036537167    0.00025261828   -3.7330328e-10        3.2295475        3.2656999
    
    Launching a checkpoint evaluation
    
      Average reward: -0.06, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
           0.05543453       0.01792883      0.036537167    0.00025261828   -3.7330328e-10        3.2295475        3.2656999
           0.05454782      0.017108975      0.036495004    0.00023871088    2.7476648e-11        3.2295475        3.2644987
    
    Launching a checkpoint evaluation
    
      Average reward: -0.09, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -1.00, redundancy: 9.0%

Training completed


Loading environment from: sessions/testing2

Starting iteration 3

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 1.9
    MCTS memory footprint per worker: 276.37MB
    Experience buffer size: 6,000 (5,290 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
          0.058607485      0.020069845       0.03742335    0.00023871088    -1.2312084e-9         3.231469        3.2665272
          0.058858033      0.020527674      0.037230212    0.00022516078   -2.0286518e-10         3.231469         3.267033
    
    Launching a checkpoint evaluation
    
      Average reward: -0.06, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
          0.058858033      0.020527674      0.037230212    0.00022516078   -2.0286518e-10         3.231469         3.267033
          0.058257278      0.020030828      0.037144996    0.00021392229     8.634422e-11         3.231469        3.2664576
    
    Launching a checkpoint evaluation
    
      Average reward: -0.03, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
          0.058257278      0.020030828      0.037144996    0.00021392229     8.634422e-11         3.231469        3.2664576
          0.058133814      0.019951623       0.03712122    0.00020180579    -4.947817e-10         3.231469        3.2672546
    
    Launching a checkpoint evaluation
    
      Average reward: -0.03, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -0.95, redundancy: 9.2%

Training completed


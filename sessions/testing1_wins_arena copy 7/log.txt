
Loading environment from: sessions/testing1_wins_arena

Starting iteration 1

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 4.4
    MCTS memory footprint per worker: 301.17MB
    Experience buffer size: 3,917 (3,499 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             4493.364        4350.9287        0.7154512     0.0003126924     2.7231981e-9        2.3696594        3.1109152
             4378.566        4238.6895        0.6318429    0.00034056098    4.3972292e-10        2.3696594         3.045798
    
    Launching a checkpoint evaluation
    
      Average reward: +0.59 (network replaced), redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             4378.566        4238.6895        0.6318429    0.00034056098    4.3972292e-10        2.3696594         3.045798
             4365.047         4225.491       0.63577986    0.00038058302     3.008545e-10        2.3696594        3.0521283
    
    Launching a checkpoint evaluation
    
      Average reward: +0.50, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             4365.047         4225.491       0.63577986    0.00038058302     3.008545e-10        2.3696594        3.0521283
             4360.647         4221.387        0.6330849    0.00039606108     1.0793074e-9        2.3696594        3.0083742
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -23.76, redundancy: 8.4%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 2

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 4.6
    MCTS memory footprint per worker: 212.32MB
    Experience buffer size: 6,000 (5,197 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            2399.8655        2306.1904        1.1118007     0.0003960611   -4.0147632e-11        1.9068067        2.9940715
            2401.2393        2306.7131        1.0633665    0.00041298664     8.205302e-10        1.9068067        3.0112302
    
    Launching a checkpoint evaluation
    
      Average reward: +0.38, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            2401.2393        2306.7131        1.0633665    0.00041298664     8.205302e-10        1.9068067        3.0112302
            2396.2822        2302.2017          1.07114    0.00042084066   -8.4398066e-10        1.9068067         2.963077
    
    Launching a checkpoint evaluation
    
      Average reward: +0.66 (network replaced), redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            2396.2822        2302.2017          1.07114    0.00042084066   -8.4398066e-10        1.9068067         2.963077
            2390.0654        2296.4392         1.076209    0.00040642635    3.1110198e-10        1.9068067         2.951827
    
    Launching a checkpoint evaluation
    
      Average reward: +0.62, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -13.36, redundancy: 7.2%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 3

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 3.6
    MCTS memory footprint per worker: 198.50MB
    Experience buffer size: 6,000 (5,118 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            17.329597       15.7817545        1.2259626    0.00040642632   -5.9088096e-10        1.7551128         2.950541
            5.1717067        3.8765113        1.1529725    0.00040908184    -1.4229024e-9        1.7551128        2.8925982
    
    Launching a checkpoint evaluation
    
      Average reward: +0.38, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            5.1717067        3.8765113        1.1529725    0.00040908184    -1.4229024e-9        1.7551128        2.8925982
            5.1123424        3.8829741        1.0932031    0.00047976244    -1.7386101e-9        1.7551128        2.8856015
    
    Launching a checkpoint evaluation
    
      Average reward: +0.41, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            5.1123424        3.8829741        1.0932031    0.00047976244    -1.7386101e-9        1.7551128        2.8856015
            5.0020003        3.7963266        1.0734787     0.0005658502     8.851949e-10        1.7551128        2.8775816
    
    Launching a checkpoint evaluation
    
      Average reward: +0.50, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -40.81, redundancy: 6.5%

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 4

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 4.1
    MCTS memory footprint per worker: 196.29MB
    Experience buffer size: 6,000 (5,019 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             9.024447        7.9512076        1.1286871     0.0005658503    1.2081046e-10        1.6994395         2.878858
             8.885446        7.8236437        1.1201077       0.00062476     6.489638e-10        1.6994395        2.8809383
    
    Launching a checkpoint evaluation
    
      Average reward: +0.78 (network replaced), redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             8.885446        7.8236437        1.1201077       0.00062476     6.489638e-10        1.6994395        2.8809383
             8.867911         7.806962        1.1210124     0.0006138662     -5.65269e-10        1.6994395        2.8940706
    
    Launching a checkpoint evaluation
    
      Average reward: +0.31, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             8.867911         7.806962        1.1210124     0.0006138662     -5.65269e-10        1.6994395        2.8940706
             8.822835         7.764265        1.1185149     0.0006768348   -8.2291124e-10        1.6994395         2.882211
    
    Launching a checkpoint evaluation
    
      Average reward: +0.28, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -80.96, redundancy: 10.1%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 5

  Starting self-play
  
    Generating 3 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 207.56MB
    Experience buffer size: 6,334 (5,592 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            26.940155        25.157227        0.7063753     0.0006768347   -6.3681405e-10        2.1600835        2.9085453
             26.39513         24.68477       0.71018064    0.00061799237   -3.5859152e-10        2.1600835         2.904071
    
    Launching a checkpoint evaluation
    
      Average reward: +0.38, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             26.39513         24.68477       0.71018064    0.00061799237   -3.5859152e-10        2.1600835         2.904071
            26.139362        24.438898        0.7095868    0.00057265285    -4.914323e-10        2.1600835        2.9127345
    
    Launching a checkpoint evaluation
    
      Average reward: +0.22, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            26.139362        24.438898        0.7095868    0.00057265285    -4.914323e-10        2.1600835        2.9127345
            26.081625        24.383905         0.711921     0.0005441578     1.2701108e-9        2.1600835        2.9146295
    
    Launching a checkpoint evaluation
    
      Average reward: +0.22, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -13.88, redundancy: 6.1%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 6

  Starting self-play
  
    Generating 3 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 190.21MB
    Experience buffer size: 6,667 (6,114 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            102.21305        100.19493        0.4717078     0.0005441579     1.3989352e-9        2.4215052        2.9269414
              101.608         99.58189       0.50095814     0.0005139486    1.6168565e-10        2.4215052        2.9294832
    
    Launching a checkpoint evaluation
    
      Average reward: +0.28, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
              101.608         99.58189       0.50095814     0.0005139486    1.6168565e-10        2.4215052        2.9294832
           101.064735         99.05942       0.49910626     0.0005265551     8.745482e-10        2.4215052        2.9215865
    
    Launching a checkpoint evaluation
    
      Average reward: +0.53, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
           101.064735         99.05942       0.49910626     0.0005265551     8.745482e-10        2.4215052        2.9215865
            100.56039        98.557915       0.50750256    0.00051631936    -1.1715868e-9        2.4215052        2.9171507
    
    Launching a checkpoint evaluation
    
      Average reward: +0.34, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -44.04, redundancy: 8.3%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 7

  Starting self-play
  
    Generating 3 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 204.49MB
    Experience buffer size: 7,000 (6,425 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             63.84491        62.899376       0.50850254    0.00051631936    5.4420113e-10        2.4070585        2.9090593
             62.68106         61.73838        0.5109231     0.0004742176   -6.1594624e-10        2.4070585        2.9458027
    
    Launching a checkpoint evaluation
    
      Average reward: +0.12, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             62.68106         61.73838        0.5109231     0.0004742176   -6.1594624e-10        2.4070585        2.9458027
              62.5218        61.564907        0.5281026    0.00048139115     7.670191e-10        2.4070585        2.9512055
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
              62.5218        61.564907        0.5281026    0.00048139115     7.670191e-10        2.4070585        2.9512055
            62.284054        61.313026        0.5450459    0.00043871166    8.0365586e-10        2.4070585        2.9545057
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -7.18, redundancy: 6.8%

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 8

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 202.40MB
    Experience buffer size: 7,000 (6,392 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             34.73042        34.236423       0.54560035    0.00043871175     1.1511582e-9        2.3994267         2.947565
             34.09164         33.59077       0.54636586     0.0003971602     -1.496357e-9        2.3994267        2.9560788
    
    Launching a checkpoint evaluation
    
      Average reward: +0.06, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             34.09164         33.59077       0.54636586     0.0003971602     -1.496357e-9        2.3994267        2.9560788
            33.872787         33.38602        0.5320294    0.00038842455    2.7093822e-10        2.3994267        2.9535067
    
    Launching a checkpoint evaluation
    
      Average reward: +0.06, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            33.872787         33.38602        0.5320294    0.00038842455    2.7093822e-10        2.3994267        2.9535067
            33.638885        33.172108       0.51058507    0.00040341268    1.1144045e-11        2.3994267        2.9295769
    
    Launching a checkpoint evaluation
    
      Average reward: +0.12, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -73.56, redundancy: 7.6%

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 9

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 203.18MB
    Experience buffer size: 7,000 (6,380 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            33.216927        32.444042       0.50592077    0.00040341273   -2.1225899e-10        2.3956065        2.9290302
            32.434753        31.697603       0.48500043    0.00047621227     6.335068e-10        2.3956065        2.9007142
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            32.434753        31.697603       0.48500043    0.00047621227     6.335068e-10        2.3956065        2.9007142
            32.424194        31.682377       0.48769018     0.0005555196   -3.8069983e-10        2.3956065         2.901997
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            32.424194        31.682377       0.48769018     0.0005555196   -3.8069983e-10        2.3956065         2.901997
            32.414173        31.675709       0.48398137    0.00060015393     2.5230154e-9        2.3956065        2.9106796
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -1.00, redundancy: 6.8%

Training completed


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


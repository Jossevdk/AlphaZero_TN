
Loading environment from: sessions/testing1_wins_arena

Starting iteration 1

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 4.4
    MCTS memory footprint per worker: 301.17MB
    Experience buffer size: 3,917 (3,499 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             4493.364        4350.9287        0.7154512     0.0003126924     2.7231981e-9        2.3696594        3.1109152
             4378.566        4238.6895        0.6318429    0.00034056098    4.3972292e-10        2.3696594         3.045798
    
    Launching a checkpoint evaluation
    
      Average reward: +0.59 (network replaced), redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             4378.566        4238.6895        0.6318429    0.00034056098    4.3972292e-10        2.3696594         3.045798
             4365.047         4225.491       0.63577986    0.00038058302     3.008545e-10        2.3696594        3.0521283
    
    Launching a checkpoint evaluation
    
      Average reward: +0.50, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             4365.047         4225.491       0.63577986    0.00038058302     3.008545e-10        2.3696594        3.0521283
             4360.647         4221.387        0.6330849    0.00039606108     1.0793074e-9        2.3696594        3.0083742
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -23.76, redundancy: 8.4%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 2

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 4.6
    MCTS memory footprint per worker: 212.32MB
    Experience buffer size: 6,000 (5,197 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            2399.8655        2306.1904        1.1118007     0.0003960611   -4.0147632e-11        1.9068067        2.9940715
            2401.2393        2306.7131        1.0633665    0.00041298664     8.205302e-10        1.9068067        3.0112302
    
    Launching a checkpoint evaluation
    
      Average reward: +0.38, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            2401.2393        2306.7131        1.0633665    0.00041298664     8.205302e-10        1.9068067        3.0112302
            2396.2822        2302.2017          1.07114    0.00042084066   -8.4398066e-10        1.9068067         2.963077
    
    Launching a checkpoint evaluation
    
      Average reward: +0.66 (network replaced), redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            2396.2822        2302.2017          1.07114    0.00042084066   -8.4398066e-10        1.9068067         2.963077
            2390.0654        2296.4392         1.076209    0.00040642635    3.1110198e-10        1.9068067         2.951827
    
    Launching a checkpoint evaluation
    
      Average reward: +0.62, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -13.36, redundancy: 7.2%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 3

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 3.6
    MCTS memory footprint per worker: 198.50MB
    Experience buffer size: 6,000 (5,118 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            17.329597       15.7817545        1.2259626    0.00040642632   -5.9088096e-10        1.7551128         2.950541
            5.1717067        3.8765113        1.1529725    0.00040908184    -1.4229024e-9        1.7551128        2.8925982
    
    Launching a checkpoint evaluation
    
      Average reward: +0.38, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            5.1717067        3.8765113        1.1529725    0.00040908184    -1.4229024e-9        1.7551128        2.8925982
            5.1123424        3.8829741        1.0932031    0.00047976244    -1.7386101e-9        1.7551128        2.8856015
    
    Launching a checkpoint evaluation
    
      Average reward: +0.41, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            5.1123424        3.8829741        1.0932031    0.00047976244    -1.7386101e-9        1.7551128        2.8856015
            5.0020003        3.7963266        1.0734787     0.0005658502     8.851949e-10        1.7551128        2.8775816
    
    Launching a checkpoint evaluation
    
      Average reward: +0.50, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -40.81, redundancy: 6.5%

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 4

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 4.1
    MCTS memory footprint per worker: 196.29MB
    Experience buffer size: 6,000 (5,019 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             9.024447        7.9512076        1.1286871     0.0005658503    1.2081046e-10        1.6994395         2.878858
             8.885446        7.8236437        1.1201077       0.00062476     6.489638e-10        1.6994395        2.8809383
    
    Launching a checkpoint evaluation
    
      Average reward: +0.78 (network replaced), redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             8.885446        7.8236437        1.1201077       0.00062476     6.489638e-10        1.6994395        2.8809383
             8.867911         7.806962        1.1210124     0.0006138662     -5.65269e-10        1.6994395        2.8940706
    
    Launching a checkpoint evaluation
    
      Average reward: +0.31, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             8.867911         7.806962        1.1210124     0.0006138662     -5.65269e-10        1.6994395        2.8940706
             8.822835         7.764265        1.1185149     0.0006768348   -8.2291124e-10        1.6994395         2.882211
    
    Launching a checkpoint evaluation
    
      Average reward: +0.28, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -80.96, redundancy: 10.1%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 5

  Starting self-play
  
    Generating 3 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 207.56MB
    Experience buffer size: 6,334 (5,592 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            26.940155        25.157227        0.7063753     0.0006768347   -6.3681405e-10        2.1600835        2.9085453
             26.39513         24.68477       0.71018064    0.00061799237   -3.5859152e-10        2.1600835         2.904071
    
    Launching a checkpoint evaluation
    
      Average reward: +0.38, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             26.39513         24.68477       0.71018064    0.00061799237   -3.5859152e-10        2.1600835         2.904071
            26.139362        24.438898        0.7095868    0.00057265285    -4.914323e-10        2.1600835        2.9127345
    
    Launching a checkpoint evaluation
    
      Average reward: +0.22, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            26.139362        24.438898        0.7095868    0.00057265285    -4.914323e-10        2.1600835        2.9127345
            26.081625        24.383905         0.711921     0.0005441578     1.2701108e-9        2.1600835        2.9146295
    
    Launching a checkpoint evaluation
    
      Average reward: +0.22, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -13.88, redundancy: 6.1%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 6

  Starting self-play
  
    Generating 3 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 190.21MB
    Experience buffer size: 6,667 (6,114 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            102.21305        100.19493        0.4717078     0.0005441579     1.3989352e-9        2.4215052        2.9269414
              101.608         99.58189       0.50095814     0.0005139486    1.6168565e-10        2.4215052        2.9294832
    
    Launching a checkpoint evaluation
    
      Average reward: +0.28, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
              101.608         99.58189       0.50095814     0.0005139486    1.6168565e-10        2.4215052        2.9294832
           101.064735         99.05942       0.49910626     0.0005265551     8.745482e-10        2.4215052        2.9215865
    
    Launching a checkpoint evaluation
    
      Average reward: +0.53, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
           101.064735         99.05942       0.49910626     0.0005265551     8.745482e-10        2.4215052        2.9215865
            100.56039        98.557915       0.50750256    0.00051631936    -1.1715868e-9        2.4215052        2.9171507
    
    Launching a checkpoint evaluation
    
      Average reward: +0.34, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -44.04, redundancy: 8.3%

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 7

  Starting self-play
  
    Generating 3 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 204.49MB
    Experience buffer size: 7,000 (6,425 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             63.84491        62.899376       0.50850254    0.00051631936    5.4420113e-10        2.4070585        2.9090593
             62.68106         61.73838        0.5109231     0.0004742176   -6.1594624e-10        2.4070585        2.9458027
    
    Launching a checkpoint evaluation
    
      Average reward: +0.12, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             62.68106         61.73838        0.5109231     0.0004742176   -6.1594624e-10        2.4070585        2.9458027
              62.5218        61.564907        0.5281026    0.00048139115     7.670191e-10        2.4070585        2.9512055
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
              62.5218        61.564907        0.5281026    0.00048139115     7.670191e-10        2.4070585        2.9512055
            62.284054        61.313026        0.5450459    0.00043871166    8.0365586e-10        2.4070585        2.9545057
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -7.18, redundancy: 6.8%

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 8

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 202.40MB
    Experience buffer size: 7,000 (6,392 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             34.73042        34.236423       0.54560035    0.00043871175     1.1511582e-9        2.3994267         2.947565
             34.09164         33.59077       0.54636586     0.0003971602     -1.496357e-9        2.3994267        2.9560788
    
    Launching a checkpoint evaluation
    
      Average reward: +0.06, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             34.09164         33.59077       0.54636586     0.0003971602     -1.496357e-9        2.3994267        2.9560788
            33.872787         33.38602        0.5320294    0.00038842455    2.7093822e-10        2.3994267        2.9535067
    
    Launching a checkpoint evaluation
    
      Average reward: +0.06, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            33.872787         33.38602        0.5320294    0.00038842455    2.7093822e-10        2.3994267        2.9535067
            33.638885        33.172108       0.51058507    0.00040341268    1.1144045e-11        2.3994267        2.9295769
    
    Launching a checkpoint evaluation
    
      Average reward: +0.12, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -73.56, redundancy: 7.6%

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 9

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 2.3
    MCTS memory footprint per worker: 203.18MB
    Experience buffer size: 7,000 (6,380 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            33.216927        32.444042       0.50592077    0.00040341273   -2.1225899e-10        2.3956065        2.9290302
            32.434753        31.697603       0.48500043    0.00047621227     6.335068e-10        2.3956065        2.9007142
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            32.434753        31.697603       0.48500043    0.00047621227     6.335068e-10        2.3956065        2.9007142
            32.424194        31.682377       0.48769018     0.0005555196   -3.8069983e-10        2.3956065         2.901997
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            32.424194        31.682377       0.48769018     0.0005555196   -3.8069983e-10        2.3956065         2.901997
            32.414173        31.675709       0.48398137    0.00060015393     2.5230154e-9        2.3956065        2.9106796
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -1.00, redundancy: 6.8%

Training completed


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Training completed


Loading environment from: sessions/testing1_wins_arena

Starting iteration 10

  Starting self-play
  
    Generating 3 samples per second on average
    Average exploration depth: 2.5
    MCTS memory footprint per worker: 201.98MB
    Experience buffer size: 7,000 (6,356 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             31.07971        30.936935       0.48382273      0.000600154   -7.5379494e-11        2.3883708         2.909246
            31.000553        30.862604       0.47590914    0.00063006894     -9.61075e-10        2.3883708         2.884524
    
    Launching a checkpoint evaluation
    
      Average reward: +0.06, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            31.000553        30.862604       0.47590914    0.00063006894     -9.61075e-10        2.3883708         2.884524
            30.950825        30.811914        0.4773237     0.0006439337   -3.3980932e-10        2.3883708         2.888609
    
    Launching a checkpoint evaluation
    
      Average reward: +0.03, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            30.950825        30.811914        0.4773237     0.0006439337   -3.3980932e-10        2.3883708         2.888609
            30.846722        30.712507        0.4722784     0.0006771871    -1.3427972e-9        2.3883708        2.9032435
    
    Launching a checkpoint evaluation
    
      Average reward: +0.06, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -25.31, redundancy: 9.4%

Training completed


Loading environment from: sessions/testing1_wins_arena_then_score

Training completed


Loading environment from: sessions/testing1_wins_arena_then_score

Training completed


Loading environment from: sessions/testing1_wins_arena_then_score

Training completed


Loading environment from: sessions/testing1_wins_arena_then_score

Training completed


Loading environment from: sessions/testing1_wins_arena_then_score

Starting iteration 11

  Starting self-play
  
    Generating 3 samples per second on average
    Average exploration depth: 2.4
    MCTS memory footprint per worker: 207.54MB
    Experience buffer size: 7,000 (6,348 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            1021.7032        1006.5351       0.47190347    0.00067718705   -8.9177377e-10        2.4048007        2.9063885
           1005.11066         989.9978       0.47640893     0.0005968276    -3.467126e-10        2.4048007         2.902706
    
    Launching a checkpoint evaluation
    
      Average reward: -4.30, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
           1005.11066         989.9978       0.47640893     0.0005968276    -3.467126e-10        2.4048007         2.902706
            1001.9364         986.8456       0.46924508     0.0006453661    -9.351108e-10        2.4048007        2.9015548
    
    Launching a checkpoint evaluation
    
      Average reward: -4.96, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            1001.9364         986.8456       0.46924508     0.0006453661    -9.351108e-10        2.4048007        2.9015548
             997.8462         982.7627        0.4738985     0.0006396449     6.860772e-10        2.4048007         2.921085
    
    Launching a checkpoint evaluation
    
      Average reward: -6.49, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -42.17, redundancy: 5.9%

Training completed


Loading environment from: sessions/testing1_wins_arena_then_score

Starting iteration 12

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 2.4
    MCTS memory footprint per worker: 205.91MB
    Experience buffer size: 7,000 (6,385 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
            699.66156         682.8646       0.46226457     0.0006396448    -6.403717e-10        2.4126945        2.9239864
             699.0774         682.3427       0.47479242    0.00059578434     4.231097e-10        2.4126945        2.9037607
    
    Launching a checkpoint evaluation
    
      Average reward: -8.63, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             699.0774         682.3427       0.47479242    0.00059578434     4.231097e-10        2.4126945        2.9037607
             697.3208        680.59033        0.4877026    0.00057628873   -7.9509965e-10        2.4126945        2.9308074
    
    Launching a checkpoint evaluation
    
      Average reward: -11.16, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             697.3208        680.59033        0.4877026    0.00057628873   -7.9509965e-10        2.4126945        2.9308074
            695.40515         678.7302       0.47692034     0.0005982687    5.8175503e-10        2.4126945        2.9264681
    
    Launching a checkpoint evaluation
    
      Average reward: -11.13, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -28.20, redundancy: 8.0%

Training completed


Loading environment from: sessions/testing1_wins_arena_then_score

Starting iteration 13

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 5.0
    MCTS memory footprint per worker: 104.85MB
    Experience buffer size: 7,000 (5,937 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             675.6936        667.68317        1.0895488    0.00059826876       1.29606e-9        1.9445035        2.9572704
             671.4328        663.49255          1.07078    0.00050529273    -1.055918e-10        1.9445035        2.9977996
    
    Launching a checkpoint evaluation
    
      Average reward: -7.20, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             671.4328        663.49255          1.07078    0.00050529273    -1.055918e-10        1.9445035        2.9977996
             668.2853        660.35345        1.0700595    0.00051543076   -2.5508015e-10        1.9445035        3.0016363
    
    Launching a checkpoint evaluation
    
      Average reward: -5.65, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             668.2853        660.35345        1.0700595    0.00051543076   -2.5508015e-10        1.9445035        3.0016363
             664.6594        656.73175        1.0726229    0.00052649126    -1.2195069e-9        1.9445035         3.003241
    
    Launching a checkpoint evaluation
    
      Average reward: -7.52, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -21.69, redundancy: 6.4%

Training completed


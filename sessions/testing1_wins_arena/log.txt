
Loading environment from: sessions/testing1_wins_arena

Starting iteration 1

  Starting self-play
  
    Generating 2 samples per second on average
    Average exploration depth: 4.4
    MCTS memory footprint per worker: 301.17MB
    Experience buffer size: 3,917 (3,499 distinct boards)
  
  Starting learning
  
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             4493.364        4350.9287        0.7154512     0.0003126924     2.7231981e-9        2.3696594        3.1109152
             4378.566        4238.6895        0.6318429    0.00034056098    4.3972292e-10        2.3696594         3.045798
    
    Launching a checkpoint evaluation
    
      Average reward: +0.59 (network replaced), redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             4378.566        4238.6895        0.6318429    0.00034056098    4.3972292e-10        2.3696594         3.045798
             4365.047         4225.491       0.63577986    0.00038058302     3.008545e-10        2.3696594        3.0521283
    
    Launching a checkpoint evaluation
    
      Average reward: +0.50, redundancy: 0.0%
    
    Optimizing the loss
    
                 Loss               Lv               Lp             Lreg             Linv               Hp            Hpnet
             4365.047         4225.491       0.63577986    0.00038058302     3.008545e-10        2.3696594        3.0521283
             4360.647         4221.387        0.6330849    0.00039606108     1.0793074e-9        2.3696594        3.0083742
    
    Launching a checkpoint evaluation
    
      Average reward: +0.00, redundancy: 0.0%
  
  Running benchmark: Network Only
  
    Average reward: -23.76, redundancy: 8.4%

Training completed

